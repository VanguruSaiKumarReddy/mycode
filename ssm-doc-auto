#!/usr/bin/env bash
set -euo pipefail

# =========================
# CONFIG (override via env)
# =========================
ROLE_NAME="${ROLE_NAME:-TFC.RL.AWS.Enterprise.BootStrapAuto}"  # cross-account role in each member acct
REGIONS=(${REGIONS:-"us-east-1" "us-east-2" "us-west-1" "us-west-2"})
ACCOUNTS_FILE="${ACCOUNTS_FILE:-accounts.txt}"                 # one account ID per line; lines starting with # are ignored

# What to run on Linux hosts (semicolon-separated shell commands)
DOC_NAME="${DOC_NAME:-AWS-RunShellScript}"                     # or your custom Linux-only doc
COMMANDS="${COMMANDS:-uname -a; whoami; echo 'hello from SSM'}"

# Fan-out safety knobs
MAX_CONCURRENCY="${MAX_CONCURRENCY:-50%}"                     # e.g. "50%" or "100"
MAX_ERRORS="${MAX_ERRORS:-10%}"                                # e.g. "10%" or "10"
BATCH_SIZE="${BATCH_SIZE:-50}"                                 # max 50 instance-ids per send-command call

# Optional: capture command output to S3 (stdout/stderr per instance)
OUTPUT_S3_BUCKET="${OUTPUT_S3_BUCKET:-}"                       # e.g., my-ops-logs
OUTPUT_S3_PREFIX="${OUTPUT_S3_PREFIX:-ssm/linux}"              # e.g., ssm/linux-$(date +%F)
OUTPUT_S3_KMS_KEY_ID="${OUTPUT_S3_KMS_KEY_ID:-}"               # optional SSE-KMS key id

# Dependencies
command -v aws >/dev/null 2>&1 || { echo "aws CLI v2 required"; exit 1; }
command -v jq  >/dev/null 2>&1 || { echo "jq required"; exit 1; }

# Globals set by assume_role()
AK=""; SK=""; ST=""

# Assume role in target account, pull temp creds
assume_role() {
  local account_id="$1"
  local region_for_sts="us-east-1"  # use regional STS to avoid partition/global endpoint oddities

  local creds
  creds=$(aws sts assume-role \
    --role-arn "arn:aws:iam::${account_id}:role/${ROLE_NAME}" \
    --role-session-name "ssm-linux-$(date +%s)" \
    --region "${region_for_sts}" \
    --query 'Credentials' \
    --output json)

  AK="$(jq -r '.AccessKeyId'     <<<"$creds")"
  SK="$(jq -r '.SecretAccessKey' <<<"$creds")"
  ST="$(jq -r '.SessionToken'    <<<"$creds")"
}

# List SSM-managed instances that are:
#   - PlatformTypes=Linux
#   - PingStatus=Online
#   - ResourceType=EC2Instance
#   - NOT Amazon Linux 2023 (PlatformName="Amazon Linux" AND PlatformVersion startswith("2023"))
list_linux_online_instances() {
  local region="$1"
  local next_token=""
  local ids=()

  while : ; do
    local args=(
      ssm describe-instance-information
      --region "$region"
      --filters "Key=PlatformTypes,Values=Linux" "Key=PingStatus,Values=Online" "Key=ResourceType,Values=EC2Instance"
      --max-results 50
      --output json
    )
    [[ -n "$next_token" ]] && args+=( --next-token "$next_token" )

    local page
    page=$(AWS_ACCESS_KEY_ID="$AK" AWS_SECRET_ACCESS_KEY="$SK" AWS_SESSION_TOKEN="$ST" aws "${args[@]}")

    # Exclude AL2023: PlatformName='Amazon Linux' AND PlatformVersion startswith('2023')
    mapfile -t page_ids < <(
      jq -r '
        .InstanceInformationList[]
        | select( (.PlatformName != "Amazon Linux") or (.PlatformVersion | startswith("2023") | not) )
        | .InstanceId
      ' <<<"$page"
    )
    [[ ${#page_ids[@]} -gt 0 ]] && ids+=("${page_ids[@]}")

    next_token="$(jq -r '.NextToken // empty' <<<"$page")"
    [[ -z "$next_token" ]] && break
  done

  printf "%s\n" "${ids[@]}" | awk 'NF'
}

# Keep only EC2 instances that are actually in state "running"
filter_running_instances() {
  local region="$1"; shift
  local -a in_ids=( "$@" )
  [[ ${#in_ids[@]} -eq 0 ]] && return 0

  local out=()
  local chunk_size=100
  local i=0
  while (( i < ${#in_ids[@]} )); do
    local chunk=( "${in_ids[@]:i:chunk_size}" )
    local lines
    lines=$(AWS_ACCESS_KEY_ID="$AK" AWS_SECRET_ACCESS_KEY="$SK" AWS_SESSION_TOKEN="$ST" \
      aws ec2 describe-instances \
        --region "$region" \
        --instance-ids "${chunk[@]}" \
        --query 'Reservations[].Instances[?State.Name==`running`].[InstanceId]' \
        --output text 2>/dev/null || true)
    if [[ -n "$lines" ]]; then
      while IFS= read -r id; do [[ -n "$id" ]] && out+=("$id"); done <<<"$lines"
    fi
    i=$(( i + chunk_size ))
  done
  printf "%s\n" "${out[@]}"
}

# Send the command to a batch of instance IDs
send_command_batch() {
  local region="$1"; shift
  local -a ids=( "$@" )
  [[ ${#ids[@]} -eq 0 ]] && return 0

  local s3_args=()
  if [[ -n "$OUTPUT_S3_BUCKET" ]]; then
    s3_args+=( --output-s3-bucket-name "$OUTPUT_S3_BUCKET" --output-s3-key-prefix "$OUTPUT_S3_PREFIX" )
    [[ -n "$OUTPUT_S3_KMS_KEY_ID" ]] && s3_args+=( --output-s3-region "$region" --output-s3-encryption-kms-key-id "$OUTPUT_S3_KMS_KEY_ID" )
  fi

  AWS_ACCESS_KEY_ID="$AK" AWS_SECRET_ACCESS_KEY="$SK" AWS_SESSION_TOKEN="$ST" \
  aws ssm send-command \
    --region "$region" \
    --document-name "$DOC_NAME" \
    --comment "Linux-only run via script (excludes AL2023; running instances only)" \
    --parameters "commands=['${COMMANDS//\'/\'\\\'\'}']" \
    --max-concurrency "$MAX_CONCURRENCY" \
    --max-errors "$MAX_ERRORS" \
    --instance-ids "${ids[@]}" \
    "${s3_args[@]}" \
    >/dev/null
}

# ==============
# MAIN
# ==============
echo "Account,Region,DiscoveredLinux,RunningAfterFilter,BatchesSubmitted"

[[ -s "$ACCOUNTS_FILE" ]] || { echo "Accounts file '$ACCOUNTS_FILE' not found or empty"; exit 1; }

# Normalize accounts file and iterate (skip comments/blank lines)
while IFS= read -r ACCOUNT_ID; do
  ACCOUNT_ID="$(echo "$ACCOUNT_ID" | awk '{$1=$1};1')"
  [[ -z "$ACCOUNT_ID" || "${ACCOUNT_ID:0:1}" == "#" ]] && continue

  assume_role "$ACCOUNT_ID"

  for REGION in "${REGIONS[@]}"; do
    # 1) Linux + Online + EC2 + not AL2023
    mapfile -t LINUX_IDS < <(list_linux_online_instances "$REGION")
    total="${#LINUX_IDS[@]}"

    # 2) Ensure EC2 state == running (exclude stopped/terminated)
    mapfile -t RUNNING_IDS < <(filter_running_instances "$REGION" "${LINUX_IDS[@]}")
    running="${#RUNNING_IDS[@]}"

    if (( running == 0 )); then
      echo "${ACCOUNT_ID},${REGION},${total},0,0"
      continue
    fi

    # 3) Batch and send
    submitted=0
    i=0
    while (( i < running )); do
      chunk=( "${RUNNING_IDS[@]:i:BATCH_SIZE}" )
      send_command_batch "$REGION" "${chunk[@]}"
      submitted=$((submitted + 1))
      i=$((i + BATCH_SIZE))
    done

    echo "${ACCOUNT_ID},${REGION},${total},${running},${submitted}"
  done
done < "$ACCOUNTS_FILE"
